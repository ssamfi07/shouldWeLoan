lala
kek
q()
print("Hello World")
yey
install.packages("tidyverse")
lab1
lab1.R
spec(ec)
str(ec)
library(tidyverse)
ec <- read.csv("echocardiogram.csv")
df_train <- read_and_preprocess("database.csv")
library(tidyverse)
library(caret)
library(corrplot)
library(ggplot2)
library(gridExtra)
# library(ggbiplot)
library(factoextra)
library(stats)
library(cluster)
library(naivebayes)
library(class)
library(rpart)
library(rpart.plot)
library(randomForest)
library(keras)
library(xgboost)
df_train <- read_and_preprocess("database.csv")
read_and_preprocess <- function(file_path) {
df <- read_csv(file_path)
print(colnames(df))
# additional preprocessing steps here
# we don't need "trans_id" or "account_id" -> remove
df <- df[, !colnames(df) %in% c("trans_id")]
df <- df[, !colnames(df) %in% c("account_id")]
df <- df[, !colnames(df) %in% c("date_y")]
df <- df[, !colnames(df) %in% c("loan_id")]
# convert data_diff to numeric
df$date_diff <- as.numeric(df$date_diff)
# convert our status target variable to binary -- 1 for paid 0 for unpaid
df$status_binary <- ifelse(df$status == 1, 1, 0)
df <- df[, !colnames(df) %in% c("status")]
# check for missing values
colSums(is.na(df))
# we have missing values in the columns "date_diff"
# so we need to change the N/A values to "0"
df$date_diff[is.na(df$date_diff)] <- 0
# check for redundant or irrelevant values (or columns)
# check for columns with 0 variance
numeric_df <- df[sapply(df, is.numeric)]
zero_variance_cols <- colnames(numeric_df)[apply(numeric_df, 2, function(x) length(unique(x))) == 1]
print(zero_variance_cols)
# no column has 0 variance
return(df)
}
df_train <- read_and_preprocess("database.csv")
setwd("~/Documents/Master/DataMining/shouldWeLoan")
df_train <- read_and_preprocess("database.csv")
print(df_train)
normalize_and_encode <- function(df) {
#normalize every numeric column (with z-score standardization), except for the target variable "status_binary"
numeric_cols <- sapply(df, is.numeric)
numeric_cols["status_binary"] <- FALSE
numeric_cols["loan_id"] <- FALSE
numeric_cols["type"] <- FALSE
df[numeric_cols] <- scale(df[numeric_cols])
#check for categorical columns
categorical_cols <- names(df)[sapply(df, function(x) is.factor(x) || is.character(x))]
print(categorical_cols)
#only the column "type" is categorical
#so we are going to label encode it
df <- df %>% mutate(type = recode(type, "credit" = 1, "withdrawal" = 2))
#(Pearson) correlation in relation to "status" (our target variable)
correlations <- sapply(df, function(col) cor(col, df$status_binary))
print(correlations)
# the columns that have almost no correlation with "status" will be dropped
# only "date_diff" and "amount_trans" will be dropped -- not sure about this step
# df <- df[, !colnames(df) %in% c("amount_trans", "date_diff")]
return(df)
}
df_preprocessed <- normalize_and_encode(df_train)
# function to perform data normalization and label encoding
normalize_and_encode <- function(df) {
#normalize every numeric column (with z-score standardization), except for the target variable "status_binary"
numeric_cols <- sapply(df, is.numeric)
numeric_cols["status_binary"] <- FALSE
numeric_cols["type"] <- FALSE
df[numeric_cols] <- scale(df[numeric_cols])
#check for categorical columns
categorical_cols <- names(df)[sapply(df, function(x) is.factor(x) || is.character(x))]
print(categorical_cols)
#only the column "type" is categorical
#so we are going to label encode it
df <- df %>% mutate(type = recode(type, "credit" = 1, "withdrawal" = 2))
#(Pearson) correlation in relation to "status" (our target variable)
correlations <- sapply(df, function(col) cor(col, df$status_binary))
print(correlations)
# the columns that have almost no correlation with "status" will be dropped
# only "date_diff" and "amount_trans" will be dropped -- not sure about this step
# df <- df[, !colnames(df) %in% c("amount_trans", "date_diff")]
return(df)
}
df_preprocessed <- normalize_and_encode(df_train)
print(df_preprocessed)
# function to perform PCA
perform_pca <- function(df) {
#PCA in relation to "loan_id"
pca <- prcomp(df, scale = TRUE)
#visual representation of the PCA (1 and 2)
biplot(pca, scale = 0, choices = c(1, 2, 3))
#new dataframe with only 2 PCs
pcs_only <- as.data.frame(pca$x[, 1:3])
#new dataframe with the original columns and the first 2 PCs
df_with_pcs <- cbind(df, pca$x[, 1:3])
return(list(pca = pca, pcs_only = pcs_only))
}
result <- perform_pca(df_preprocessed)
# function to perform PCA
perform_pca <- function(df) {
#PCA in relation to "loan_id"
pca <- prcomp(df, scale = TRUE)
#visual representation of the PCA (1 and 2)
biplot(pca, scale = 0, choices = c(1, 3))
#new dataframe with only 2 PCs
pcs_only <- as.data.frame(pca$x[, 1:3])
#new dataframe with the original columns and the first 2 PCs
df_with_pcs <- cbind(df, pca$x[, 1:3])
return(list(pca = pca, pcs_only = pcs_only))
}
# function to perform PCA
perform_pca <- function(df) {
#PCA in relation to "loan_id"
pca <- prcomp(df, scale = TRUE)
#visual representation of the PCA (1 and 2)
biplot(pca, scale = 0, choices = c(1, 3))
#new dataframe with only 2 PCs
pcs_only <- as.data.frame(pca$x[, 1:3])
#new dataframe with the original columns and the first 2 PCs
df_with_pcs <- cbind(df, pca$x[, 1:3])
return(list(pca = pca, pcs_only = pcs_only))
}
result <- perform_pca(df_preprocessed)
